{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código Clasificación buques mercantes utilizando 4 capas de CNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### Conocer version de paquetes y Hardware en uso\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "### Conocer version de paquetes y Hardware en uso\n",
    "#------------------------------------------------------\n",
    "#------------------------------------------------------\n",
    "import sys\n",
    "import tensorflow.keras\n",
    "import keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import platform\n",
    "\n",
    "print(f\"Plataforma (Software-Hardware): {platform.platform()}\")\n",
    "print(f\"Versión de Python {sys.version}\")\n",
    "print(f\"Versión de TensorFlow: {tf.__version__}\")\n",
    "print(f\"versión de Pandas {pd.__version__}\")\n",
    "print(f\"versión de Numpy {np.__version__}\")\n",
    "print(f\"versión de Keras {keras.__version__}\")\n",
    "print(f\"Versión de Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU está\", \"Disponible\" if gpu else \"No Disponible\")\n",
    "#---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "altura, longitud = 100, 100\n",
    "\n",
    "def cargar_y_redimensionar_imagenes(ruta):\n",
    "    imagenes_redimensionadas = []\n",
    "    for archivo in os.listdir(ruta):\n",
    "        archivo_ruta = os.path.join(ruta, archivo)\n",
    "        # Verificamos si el archivo es una imagen válida antes de abrirlo con OpenCV\n",
    "        imagen = cv2.imread(archivo_ruta)\n",
    "        if imagen is not None and len(imagen.shape) == 3 and imagen.shape[2] == 3:\n",
    "            imagen = cv2.resize(imagen, (altura, longitud))\n",
    "            imagenes_redimensionadas.append(imagen)\n",
    "    return imagenes_redimensionadas\n",
    "\n",
    "# Rutas de los directorios de imágenes\n",
    "ruta_mercantes = './datos/mercantes'\n",
    "ruta_otros = './datos/otros'\n",
    "\n",
    "# Cargar y redimensionar imágenes de mercantes y otros\n",
    "imagenes_mercantes = cargar_y_redimensionar_imagenes(ruta_mercantes)\n",
    "imagenes_otros = cargar_y_redimensionar_imagenes(ruta_otros)\n",
    "\n",
    "# Obtener la cantidad de imágenes en cada directorio\n",
    "dircount = [len(imagenes_mercantes), len(imagenes_otros)]\n",
    "\n",
    "print('Imagenes en cada directorio:', dircount)\n",
    "print('Suma Total de imagenes en subdirectorios:', sum(dircount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear etiquetas y clases\n",
    "\n",
    "**Creamos los labels con valor 1 para mercante y 0 para otros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista de etiquetas (0 para mercantes, 1 para otros)\n",
    "etiquetas_mercantes = [0] * len(imagenes_mercantes)\n",
    "etiquetas_otros = [1] * len(imagenes_otros)\n",
    "\n",
    "# Combinar las imágenes y etiquetas en un solo conjunto de datos\n",
    "imagenes = imagenes_mercantes + imagenes_otros\n",
    "etiquetas = etiquetas_mercantes + etiquetas_otros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos sets de Entrenamiento y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a arreglos NumPy\n",
    "X = np.array(imagenes, dtype=np.uint8)\n",
    "y = np.array(etiquetas)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y validación (80% para entrenamiento, 20% para validación)\n",
    "train_X, valid_X, train_label, valid_label = train_test_split(X, y, test_size=0.2, random_state=218) #num de cadete\n",
    "\n",
    "train_X = train_X / 255.\n",
    "valid_X = valid_X / 255.\n",
    "\n",
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(train_label)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs:', nClasses)\n",
    "print('Output classes:', classes)\n",
    "\n",
    "train_label_one_hot = to_categorical(train_label, num_classes=nClasses)\n",
    "valid_label_one_hot = to_categorical(valid_label, num_classes=nClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar las transformaciones de data augmentation\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,         # Rango de rotación aleatoria (en grados)\n",
    "    width_shift_range=0.2,     # Rango de traslación horizontal aleatoria (como fracción del ancho total)\n",
    "    height_shift_range=0.2,    # Rango de traslación vertical aleatoria (como fracción del alto total)\n",
    "    shear_range=0.2,           # Rango de cizallamiento (shear) aleatorio\n",
    "    zoom_range=0.2,            # Rango de zoom aleatorio\n",
    "    horizontal_flip=True,      # Volteo horizontal aleatorio\n",
    "    fill_mode='nearest'        # Modo de rellenado para las transformaciones\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos la red neuronal de 4 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout (0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "\n",
    "INIT_LR = 0.001#1e-3 \n",
    "\n",
    "filtrosConv1=32 #despoues de la 1ra conv, la imagen va a tener prof de 32\n",
    "filtrosConv2=64 #despjes de la 2da, tendra 64\n",
    "filtrosConv3=128\n",
    "filtrosConv4=256\n",
    "tamano_filtro1=(3,3)\n",
    "tamano_filtro2=(3,3)\n",
    "tamano_filtro3=(3,3)\n",
    "tamano_filtro4=(3,3)\n",
    "tamano_pool=(2,2)\n",
    "\n",
    "modelo1 = Sequential(name='dropout_0.3')\n",
    "modelo1.add(Convolution2D(filtrosConv1, tamano_filtro1, padding='same', input_shape=(altura,longitud,3),activation='relu'))\n",
    "modelo1.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "\n",
    "#segunda capa de convolucion (), seguida de una capa de max pooling\n",
    "modelo1.add(Convolution2D(filtrosConv2, tamano_filtro2, padding='same', activation='relu'))\n",
    "modelo1.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "\n",
    "#modelo1.add(Convolution2D(filtrosConv3, tamano_filtro3, padding='same', activation='relu'))\n",
    "#modelo1.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "\n",
    "#modelo1.add(Convolution2D(filtrosConv4, tamano_filtro4, padding='same', activation='relu'))\n",
    "\n",
    "#capa que aplana la imagen (1D)\n",
    "modelo1.add(Flatten())\n",
    "\n",
    "#capa normal, de 256 neuronas\n",
    "modelo1.add(Dense(256,activation='relu'))\n",
    "\n",
    "#capa que apagara el 50% de las neuronas en cada paso, para evitar el overfitting\n",
    "modelo1.add(Dropout(0.3))\n",
    "\n",
    "#ultima capa, que son 2 neuronas (una por clase) donde dara % prob da cada clase\n",
    "modelo1.add(Dense(nClasses,activation='softmax'))\n",
    "\n",
    "#con Graphviz se puede hacer un diagrama de flujo para ver la logica del sistema\n",
    "modelo1.summary()\n",
    "\n",
    "modelo1.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(learning_rate=INIT_LR),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamos la red\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "# Crear el generador de datos para el conjunto de entrenamiento con data augmentation\n",
    "train_data_generator = data_augmentation.flow(train_X, train_label_one_hot, batch_size=batch_size)\n",
    "\n",
    "## Modifica el train_x para incluir las imagenes del train_data_generator\n",
    "history1=modelo1.fit(train_data_generator, steps_per_epoch=len(train_X) // batch_size, epochs=epochs, verbose=1, validation_data=(valid_X, valid_label_one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtenemos las métricas de entrenamiento y validación, luego graficamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "def metricas(clases_reales, clases_predichas):\n",
    "    matriz_conf=confusion_matrix(clases_reales, clases_predichas)\n",
    "    accuracy=accuracy_score(clases_reales,clases_predichas)\n",
    "    precision=precision_score(clases_reales,clases_predichas)\n",
    "    recall=recall_score(clases_reales,clases_predichas)\n",
    "    f1=f1_score(clases_reales,clases_predichas)\n",
    "    return matriz_conf, accuracy, recall, precision, f1\n",
    "\n",
    "def visualizar_metricas(clases_reales,clases_predichas, titulo):\n",
    "    #Calculamos metricas con la funcion previa\n",
    "    matriz, accuracy, recall, precision, f1=metricas(clases_reales,clases_predichas)\n",
    "\n",
    "    #Graficamos\n",
    "    plt.figure(figsize=(3,3))\n",
    "    matriz=pd.DataFrame(matriz,columns=['0: Mercante', '1: Otro'])\n",
    "    plt.matshow(matriz, cmap=\"Blues\", vmin=0, vmax=10, fignum=1)\n",
    "    plt.title(\"Reales\")\n",
    "    plt.ylabel(\"Predichas\")\n",
    "    plt.xticks(range(len(matriz.columns)), matriz.columns, rotation=45)\n",
    "    plt.yticks(range(len(matriz.columns)), matriz.columns)\n",
    "    etiquetas = ((\"Verdaderos\\nnegativos\", \"Falsos\\npositivos\"),\n",
    "                 (\"Falsos\\nnegativos\", \"Verdaderos\\npositivos\"))\n",
    "    for i in range(len(matriz.columns)):\n",
    "        for j in range(len(matriz.columns)):\n",
    "            plt.text(i, j + 0.14, str(matriz.iloc[i, j]),\n",
    "                     fontsize=30, ha=\"center\", va=\"center\")\n",
    "            plt.text(i, j - 0.25, etiquetas[i][j],\n",
    "                     fontsize=11.5, ha=\"center\", va=\"center\")           \n",
    "    plt.text(1.60, -0.30, titulo, fontsize=25, c=\"red\")\n",
    "    plt.text(2.1, 0.10, \"Accuracy: %0.2f\" % accuracy, fontsize=20)\n",
    "    plt.text(2.1, 0.40, \"Precision: %0.2f\" % precision, fontsize=20)\n",
    "    plt.text(2.1, 0.70, \"Recall: %0.2f\" % recall, fontsize=20)\n",
    "    plt.text(2.1, 1.00, \"F1: %0.2f\" % f1, fontsize=20)    \n",
    "    plt.show()\n",
    "    print(\"\\n\")\n",
    "\n",
    "#print(\"\\n\")\n",
    "\n",
    "#reales=[1,1,0,0,0,0,1,1]\n",
    "#predichas=[1,1,0,1,0,1,1,1]\n",
    "\n",
    "#visualizar_metricas(reales,predichas,'Métricas')\n",
    "\n",
    "import seaborn as sns\n",
    "predicciones = modelo1.predict(valid_X)\n",
    "clases_predichas = np.argmax(predicciones, axis=1)\n",
    "matriz_confusion = confusion_matrix(valid_label, clases_predichas)\n",
    "etiquetas_clases=['Mercante','No Mercante']\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(matriz_confusion, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=etiquetas_clases, yticklabels=etiquetas_clases)\n",
    "plt.xlabel('Clase Predicha')\n",
    "plt.ylabel('Clase Real')\n",
    "plt.title('Matriz de Confusión del Modelo CNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas dropout 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las métricas de entrenamiento y validación\n",
    "train_accuracy = history1.history['accuracy']\n",
    "val_accuracy = history1.history['val_accuracy']\n",
    "train_loss = history1.history['loss']\n",
    "val_loss = history1.history['val_loss']\n",
    "epochs_range = range(1, epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "\n",
    "# Gráfica de precisión (accuracy)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs_range, train_accuracy, label='Training Accuracy', color='blue')\n",
    "plt.plot(epochs_range, val_accuracy, label='Validation Accuracy', color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy with 4 Layers and Dropot 0.3')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "# Gráfica de pérdida (loss)\n",
    "plt.plot(epochs_range, train_loss, label='Training Loss', color='blue')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss', color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss with 4 Layers and Dropot 0.3')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probamos la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra de Etiqueta Mercante:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(plt.imread('prueba/4.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "\n",
    "directorio_imagen_prueba='./prueba/4.jpg'\n",
    "# Carga la imagen de prueba\n",
    "imagen_prueba = cv2.imread(directorio_imagen_prueba)\n",
    "imagen_prueba = cv2.resize(imagen_prueba, (100, 100))\n",
    "\n",
    "# OpenCV lee las imágenes en formato BGR, pero los modelos de Keras están entrenados con imágenes en formato RGB, por lo que es necesario convertir la imagen de BGR a RGB\n",
    "imagen_prueba = cv2.cvtColor(imagen_prueba, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convertir a float32 y normalizar\n",
    "imagen_prueba = imagen_prueba.astype('float32') / 255.0\n",
    "\n",
    "# Ajusta las dimensiones de la imagen para que sea compatible con la entrada del modelo\n",
    "imagen_prueba = np.expand_dims(imagen_prueba, axis=0)\n",
    "\n",
    "# Obtén las predicciones utilizando el modelo entrenado\n",
    "predicciones = modelo1.predict(imagen_prueba)\n",
    "\n",
    "# Las predicciones son un arreglo de probabilidades, conviértelas a una clase\n",
    "clase_predicha = np.argmax(predicciones[0])\n",
    "\n",
    "# Obten la clase correspondiente al índice\n",
    "clase = classes[clase_predicha]\n",
    "\n",
    "# Obten el porcentaje de confianza para la clase predicha\n",
    "porcentaje_confianza = predicciones[0][clase_predicha] * 100\n",
    "\n",
    "# Carga la imagen de nuevo para mostrarla (esta vez en formato RGB para matplotlib)\n",
    "imagen_prueba = cv2.cvtColor(cv2.imread(directorio_imagen_prueba), cv2.COLOR_BGR2RGB)\n",
    "imagen_prueba = cv2.resize(imagen_prueba, (100, 100))\n",
    "imagen_array = np.array(imagen_prueba) # Arreglo de pixeles de la imagen\n",
    "\n",
    "plt.imshow(imagen_prueba)\n",
    "plt.title(\"La imagen es de clase: {} con un porcentaje de confianza de: {:.2f}%\".format(clase, porcentaje_confianza))\n",
    "plt.show()\n",
    "\n",
    "imagen_prueba1=cv2.resize(imagen_prueba, (30, 30))\n",
    "imagen_array1=np.array(imagen_prueba1)\n",
    "# Aproximar los valores de píxeles a la unidad\n",
    "imagen_pixeles = np.round(color.rgb2gray(imagen_array1) * 255).astype(int)\n",
    "\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "print(f'\\nArreglo de pixeles de la imagen:\\n {imagen_pixeles}') #Valores entre 0 y 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prueba_modelo(modelo, directorio, altura, longitud, classes):\n",
    "    resultados = []\n",
    "    for archivo in os.listdir(directorio):\n",
    "        ruta_imagen = os.path.join(directorio, archivo)\n",
    "        # Carga la imagen de prueba\n",
    "        imagen_prueba = cv2.imread(ruta_imagen)\n",
    "        imagen_prueba = cv2.resize(imagen_prueba, (altura, longitud))\n",
    "\n",
    "        # OpenCV lee las imágenes en formato BGR, pero los modelos de Keras están entrenados con imágenes en formato RGB, por lo que es necesario convertir la imagen de BGR a RGB\n",
    "        imagen_prueba = cv2.cvtColor(imagen_prueba, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Convertir a float32 y normalizar\n",
    "        imagen_prueba = imagen_prueba.astype('float32') / 255.0\n",
    "\n",
    "        # Ajusta las dimensiones de la imagen para que sea compatible con la entrada del modelo\n",
    "        imagen_prueba = np.expand_dims(imagen_prueba, axis=0)\n",
    "\n",
    "        # Obtén las predicciones utilizando el modelo entrenado\n",
    "        predicciones = modelo.predict(imagen_prueba)\n",
    "\n",
    "        # Las predicciones son un arreglo de probabilidades, conviértelas a una clase\n",
    "        clase_predicha = np.argmax(predicciones[0])\n",
    "\n",
    "        # Obten la clase correspondiente al índice\n",
    "        clase = classes[clase_predicha]\n",
    "\n",
    "        resultados.append((archivo, clase))\n",
    "\n",
    "    return resultados\n",
    "\n",
    "# Uso de la función prueba_modelo\n",
    "directorio_imagenes = './prueba'\n",
    "resultados = prueba_modelo(modelo, directorio_imagenes, altura, longitud, classes)\n",
    "\n",
    "# Mostrar resultados\n",
    "for archivo, clase in resultados:\n",
    "    print(f\"La imagen {archivo} es de clase: {clase}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
